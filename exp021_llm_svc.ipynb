{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from cuml.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "# from sklearn.svm import SVC # gpuがなければこっち"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "clothing_master_df = pd.read_csv(\"../data/clothing_master.csv\")\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_column_names = {\n",
    "    \"Clothing ID\": \"clothing_id\",\n",
    "    \"Age\": \"age\",\n",
    "    \"Title\": \"title\",\n",
    "    \"Review Text\": \"review_text\",\n",
    "    \"Rating\": \"rating\",\n",
    "    \"Recommended IND\": \"recommended\",\n",
    "    \"Positive Feedback Count\": \"positive_feedback_count\",\n",
    "}\n",
    "\n",
    "test_column_names = {\n",
    "    \"Clothing ID\": \"clothing_id\",\n",
    "    \"Age\": \"age\",\n",
    "    \"Title\": \"title\",\n",
    "    \"Review Text\": \"review_text\",\n",
    "}\n",
    "\n",
    "clothing_master_column_names = {\n",
    "    \"Clothing ID\": \"clothing_id\",\n",
    "    \"Division Name\": \"division_name\",\n",
    "    \"Department Name\": \"department_name\",\n",
    "    \"Class Name\": \"class_name\",\n",
    "}\n",
    "\n",
    "train_df = train_df.rename(columns=train_column_names)\n",
    "test_df = test_df.rename(columns=test_column_names)\n",
    "clothing_master_df = clothing_master_df.rename(columns=clothing_master_column_names)\n",
    "\n",
    "train_df = pd.merge(train_df, clothing_master_df, on=\"clothing_id\", how=\"left\")\n",
    "test_df = pd.merge(test_df, clothing_master_df, on=\"clothing_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, texts, max_length=192, tokenizer=None):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        token = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": torch.LongTensor(token[\"input_ids\"]),\n",
    "            \"attention_mask\": torch.LongTensor(token[\"attention_mask\"]),\n",
    "            \"token_type_ids\": torch.LongTensor(token[\"token_type_ids\"]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccdf799e9e04826a2f7ad4cc52455ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"intfloat/e5-mistral-7b-instruct\"\n",
    "file_name = \"e5_mistral\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def create_text_column(df: pd.DataFrame, sep_token: str) -> pd.DataFrame:\n",
    "    sep_token = \" \" if sep_token is None else sep_token\n",
    "    text_df = df.copy()\n",
    "    text_df[\"text\"] = (\n",
    "        \"Instruction: Does the reviewer recommend the clothes based on the review and title?\"\n",
    "        \". The Reiviewer's age is: <\"\n",
    "        + text_df[\"age\"].fillna(\"nan\").astype(str)\n",
    "        + \">. The review title is: <\"\n",
    "        + text_df[\"title\"].fillna(\"nan\").astype(str)\n",
    "        + \">. The review text is: <\"\n",
    "        + text_df[\"review_text\"].fillna(\"nan\").astype(str)\n",
    "        + \">. Will the reviewer recommend this cloth?\"\n",
    "    )\n",
    "    return text_df\n",
    "\n",
    "\n",
    "train_df = create_text_column(train_df, sep_token=tokenizer.sep_token)\n",
    "test_df = create_text_column(test_df, sep_token=tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = input_mask_expanded.sum(1)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "embeddings = {}\n",
    "for key, df in zip([\"train\", \"test\"], [train_df, test_df]):\n",
    "    emb_list = []\n",
    "    dataset = EmbDataset(df[\"text\"].values, max_length=192, tokenizer=tokenizer)\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    bar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for iter_i, batch in bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "            batch_embs = mean_pooling(outputs.last_hidden_state, attention_mask)\n",
    "        emb_list.append(batch_embs.detach().cpu().numpy())\n",
    "    embeddings[key] = np.concatenate(emb_list)\n",
    "\n",
    "\n",
    "def create_embedding_df(text_embeddings: np.array) -> pd.DataFrame:\n",
    "    text_columns = [f\"embedding_{i}\" for i in range(text_embeddings.shape[1])]\n",
    "\n",
    "    embedding_df = pd.DataFrame(\n",
    "        {\n",
    "            **dict(zip(text_columns, text_embeddings.T)),\n",
    "        }\n",
    "    )\n",
    "    return embedding_df\n",
    "\n",
    "\n",
    "train_embedding_df = create_embedding_df(embeddings[\"train\"])\n",
    "test_embedding_df = create_embedding_df(embeddings[\"test\"])\n",
    "\n",
    "train_embedding_df.to_csv(f\"../outputs/train_embedding_{file_name}.csv\", index=False)\n",
    "test_embedding_df.to_csv(f\"../outputs/test_embedding_{file_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_df = pd.read_csv(f\"../outputs/train_embedding_{file_name}.csv\")\n",
    "test_embedding_df = pd.read_csv(f\"../outputs/test_embedding_{file_name}.csv\")\n",
    "\n",
    "embedding_feature_names = train_embedding_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_4086</th>\n",
       "      <th>embedding_4087</th>\n",
       "      <th>embedding_4088</th>\n",
       "      <th>embedding_4089</th>\n",
       "      <th>embedding_4090</th>\n",
       "      <th>embedding_4091</th>\n",
       "      <th>embedding_4092</th>\n",
       "      <th>embedding_4093</th>\n",
       "      <th>embedding_4094</th>\n",
       "      <th>embedding_4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33800</td>\n",
       "      <td>2.717</td>\n",
       "      <td>2.230</td>\n",
       "      <td>-0.70460</td>\n",
       "      <td>0.5537</td>\n",
       "      <td>-3.908</td>\n",
       "      <td>-2.1930</td>\n",
       "      <td>4.504</td>\n",
       "      <td>1.4950</td>\n",
       "      <td>-2.865</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.258</td>\n",
       "      <td>0.47490</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>2.9700</td>\n",
       "      <td>2.658</td>\n",
       "      <td>13.850</td>\n",
       "      <td>3.473</td>\n",
       "      <td>1.1460</td>\n",
       "      <td>-0.5093</td>\n",
       "      <td>2.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.93000</td>\n",
       "      <td>3.414</td>\n",
       "      <td>1.290</td>\n",
       "      <td>-1.75000</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>-3.451</td>\n",
       "      <td>-3.4860</td>\n",
       "      <td>4.680</td>\n",
       "      <td>0.7593</td>\n",
       "      <td>-4.562</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>0.48300</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>1.125</td>\n",
       "      <td>12.360</td>\n",
       "      <td>1.647</td>\n",
       "      <td>2.0020</td>\n",
       "      <td>-2.5820</td>\n",
       "      <td>1.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.77000</td>\n",
       "      <td>3.533</td>\n",
       "      <td>1.726</td>\n",
       "      <td>-0.05994</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>-4.043</td>\n",
       "      <td>-4.4800</td>\n",
       "      <td>5.434</td>\n",
       "      <td>1.5150</td>\n",
       "      <td>-2.418</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.10400</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>2.2870</td>\n",
       "      <td>2.947</td>\n",
       "      <td>7.250</td>\n",
       "      <td>3.842</td>\n",
       "      <td>1.3080</td>\n",
       "      <td>-1.2250</td>\n",
       "      <td>1.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.08655</td>\n",
       "      <td>4.010</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-2.12000</td>\n",
       "      <td>1.1880</td>\n",
       "      <td>-3.865</td>\n",
       "      <td>-2.8050</td>\n",
       "      <td>3.880</td>\n",
       "      <td>1.3040</td>\n",
       "      <td>-3.105</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.127</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>2.7130</td>\n",
       "      <td>2.357</td>\n",
       "      <td>17.730</td>\n",
       "      <td>1.693</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>-1.2750</td>\n",
       "      <td>2.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46600</td>\n",
       "      <td>3.111</td>\n",
       "      <td>1.509</td>\n",
       "      <td>-1.18400</td>\n",
       "      <td>1.4795</td>\n",
       "      <td>-4.980</td>\n",
       "      <td>-1.9070</td>\n",
       "      <td>4.152</td>\n",
       "      <td>1.4380</td>\n",
       "      <td>-2.244</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.033</td>\n",
       "      <td>-0.55800</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>1.902</td>\n",
       "      <td>-0.658</td>\n",
       "      <td>1.731</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>-1.2560</td>\n",
       "      <td>2.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.37800</td>\n",
       "      <td>2.254</td>\n",
       "      <td>1.872</td>\n",
       "      <td>-0.07196</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>-4.266</td>\n",
       "      <td>-1.8530</td>\n",
       "      <td>3.572</td>\n",
       "      <td>1.7460</td>\n",
       "      <td>-3.463</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.129</td>\n",
       "      <td>0.39800</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>5.6450</td>\n",
       "      <td>1.859</td>\n",
       "      <td>14.030</td>\n",
       "      <td>3.793</td>\n",
       "      <td>1.1190</td>\n",
       "      <td>-3.7010</td>\n",
       "      <td>1.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.53500</td>\n",
       "      <td>3.516</td>\n",
       "      <td>1.463</td>\n",
       "      <td>-1.77000</td>\n",
       "      <td>0.4807</td>\n",
       "      <td>-5.660</td>\n",
       "      <td>-1.2690</td>\n",
       "      <td>4.484</td>\n",
       "      <td>2.3440</td>\n",
       "      <td>-3.994</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.512</td>\n",
       "      <td>-0.17330</td>\n",
       "      <td>0.8335</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>1.623</td>\n",
       "      <td>11.540</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>-1.8240</td>\n",
       "      <td>1.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.20310</td>\n",
       "      <td>2.893</td>\n",
       "      <td>0.806</td>\n",
       "      <td>-1.07200</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>-3.635</td>\n",
       "      <td>-3.0000</td>\n",
       "      <td>4.594</td>\n",
       "      <td>1.7190</td>\n",
       "      <td>-1.063</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.039</td>\n",
       "      <td>-0.27540</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>2.2600</td>\n",
       "      <td>2.383</td>\n",
       "      <td>5.695</td>\n",
       "      <td>3.918</td>\n",
       "      <td>1.0090</td>\n",
       "      <td>-2.3570</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.43290</td>\n",
       "      <td>1.993</td>\n",
       "      <td>1.505</td>\n",
       "      <td>-1.59300</td>\n",
       "      <td>0.4797</td>\n",
       "      <td>-5.110</td>\n",
       "      <td>-1.6370</td>\n",
       "      <td>4.203</td>\n",
       "      <td>2.3280</td>\n",
       "      <td>-3.213</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.579</td>\n",
       "      <td>0.31050</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>2.8100</td>\n",
       "      <td>1.652</td>\n",
       "      <td>16.080</td>\n",
       "      <td>2.613</td>\n",
       "      <td>1.6600</td>\n",
       "      <td>-2.1900</td>\n",
       "      <td>1.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.83900</td>\n",
       "      <td>2.979</td>\n",
       "      <td>1.635</td>\n",
       "      <td>-0.94400</td>\n",
       "      <td>0.8213</td>\n",
       "      <td>-5.190</td>\n",
       "      <td>-0.6133</td>\n",
       "      <td>3.610</td>\n",
       "      <td>1.9080</td>\n",
       "      <td>-3.912</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.336</td>\n",
       "      <td>0.62740</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>3.5200</td>\n",
       "      <td>2.191</td>\n",
       "      <td>14.190</td>\n",
       "      <td>3.934</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>-1.9000</td>\n",
       "      <td>2.115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0        -0.33800        2.717        2.230     -0.70460       0.5537   \n",
       "1        -0.93000        3.414        1.290     -1.75000       0.6530   \n",
       "2        -0.77000        3.533        1.726     -0.05994       0.5317   \n",
       "3         0.08655        4.010        1.444     -2.12000       1.1880   \n",
       "4         0.46600        3.111        1.509     -1.18400       1.4795   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995      1.37800        2.254        1.872     -0.07196       0.4004   \n",
       "9996      0.53500        3.516        1.463     -1.77000       0.4807   \n",
       "9997      0.20310        2.893        0.806     -1.07200       0.6560   \n",
       "9998     -0.43290        1.993        1.505     -1.59300       0.4797   \n",
       "9999      0.83900        2.979        1.635     -0.94400       0.8213   \n",
       "\n",
       "      embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
       "0          -3.908      -2.1930        4.504       1.4950       -2.865  ...   \n",
       "1          -3.451      -3.4860        4.680       0.7593       -4.562  ...   \n",
       "2          -4.043      -4.4800        5.434       1.5150       -2.418  ...   \n",
       "3          -3.865      -2.8050        3.880       1.3040       -3.105  ...   \n",
       "4          -4.980      -1.9070        4.152       1.4380       -2.244  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "9995       -4.266      -1.8530        3.572       1.7460       -3.463  ...   \n",
       "9996       -5.660      -1.2690        4.484       2.3440       -3.994  ...   \n",
       "9997       -3.635      -3.0000        4.594       1.7190       -1.063  ...   \n",
       "9998       -5.110      -1.6370        4.203       2.3280       -3.213  ...   \n",
       "9999       -5.190      -0.6133        3.610       1.9080       -3.912  ...   \n",
       "\n",
       "      embedding_4086  embedding_4087  embedding_4088  embedding_4089  \\\n",
       "0             -2.258         0.47490          0.7007          2.9700   \n",
       "1             -1.515         0.48300          0.8660          2.1200   \n",
       "2             -1.033        -1.10400          0.2095          2.2870   \n",
       "3             -2.127         0.01685          1.1250          2.7130   \n",
       "4             -2.033        -0.55800          0.7036          0.2438   \n",
       "...              ...             ...             ...             ...   \n",
       "9995          -2.129         0.39800          0.5810          5.6450   \n",
       "9996          -1.512        -0.17330          0.8335          2.1250   \n",
       "9997          -1.039        -0.27540          0.6850          2.2600   \n",
       "9998          -1.579         0.31050          0.1473          2.8100   \n",
       "9999          -2.336         0.62740          0.9120          3.5200   \n",
       "\n",
       "      embedding_4090  embedding_4091  embedding_4092  embedding_4093  \\\n",
       "0              2.658          13.850           3.473          1.1460   \n",
       "1              1.125          12.360           1.647          2.0020   \n",
       "2              2.947           7.250           3.842          1.3080   \n",
       "3              2.357          17.730           1.693          0.8560   \n",
       "4              1.902          -0.658           1.731          0.9077   \n",
       "...              ...             ...             ...             ...   \n",
       "9995           1.859          14.030           3.793          1.1190   \n",
       "9996           1.623          11.540           4.000          0.8086   \n",
       "9997           2.383           5.695           3.918          1.0090   \n",
       "9998           1.652          16.080           2.613          1.6600   \n",
       "9999           2.191          14.190           3.934          0.8164   \n",
       "\n",
       "      embedding_4094  embedding_4095  \n",
       "0            -0.5093           2.059  \n",
       "1            -2.5820           1.602  \n",
       "2            -1.2250           1.265  \n",
       "3            -1.2750           2.450  \n",
       "4            -1.2560           2.209  \n",
       "...              ...             ...  \n",
       "9995         -3.7010           1.421  \n",
       "9996         -1.8240           1.656  \n",
       "9997         -2.3570           0.510  \n",
       "9998         -2.1900           1.560  \n",
       "9999         -1.9000           2.115  \n",
       "\n",
       "[10000 rows x 4096 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.963326594457147\n",
      "AUC: 0.9657174526708527\n",
      "AUC: 0.9658384146341463\n",
      "AUC: 0.9591353319783197\n",
      "AUC: 0.9700423441734417\n",
      "Overall AUC:  0.9648\n"
     ]
    }
   ],
   "source": [
    "labels = train_df[\"recommended\"].to_numpy()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "oof = np.zeros_like(labels, dtype=float)\n",
    "test_preds = []\n",
    "\n",
    "for train_index, valid_index in cv.split(train_df, labels):\n",
    "    train_features = train_embedding_df.iloc[train_index].reset_index(drop=True)\n",
    "    valid_features = train_embedding_df.iloc[valid_index].reset_index(drop=True)\n",
    "\n",
    "    train_labels = labels[train_index]\n",
    "    valid_labels = labels[valid_index]\n",
    "\n",
    "    model = SVC(probability=True)\n",
    "    model.fit(train_features, train_labels)\n",
    "\n",
    "    valid_pred = model.predict_proba(valid_features).to_numpy()[:, 1]\n",
    "    oof[valid_index] = valid_pred\n",
    "    test_pred = model.predict_proba(test_embedding_df).to_numpy()[:, 1]\n",
    "    test_preds.append(test_pred)\n",
    "\n",
    "    auc = roc_auc_score(valid_labels, valid_pred)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "test_preds = np.mean(test_preds, axis=0)\n",
    "pickle.dump(oof, open(f\"../outputs/oof{exp}.pkl\", \"wb\"))\n",
    "overall_auc = roc_auc_score(labels, oof)\n",
    "print(f\"Overall AUC: {overall_auc: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.370026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11150</th>\n",
       "      <td>0.986862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11151</th>\n",
       "      <td>0.991425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11152</th>\n",
       "      <td>0.996870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11153</th>\n",
       "      <td>0.978660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11154</th>\n",
       "      <td>0.998638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11155 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target\n",
       "0      0.996966\n",
       "1      0.847690\n",
       "2      0.991780\n",
       "3      0.370026\n",
       "4      0.937510\n",
       "...         ...\n",
       "11150  0.986862\n",
       "11151  0.991425\n",
       "11152  0.996870\n",
       "11153  0.978660\n",
       "11154  0.998638\n",
       "\n",
       "[11155 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission_df[\"target\"] = test_preds\n",
    "sample_submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df.to_csv(f\"../outputs/submission_{exp}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
